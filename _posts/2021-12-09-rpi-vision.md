---
layout: post
title: Computer Vision with Raspberry Pi
subtitle: Project in CIS521
cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/rpi-cv.png
share-img: /assets/img/rpi-cv.jpg
tags: [raspberry pi, computer vision]
---


In this project, students were given the opportunity to apply computer vision to both real-world and highly-relevant problems.  Face Recognition is a common technology in modern smartphones and laptops with webcams.  These systems extract visual keypoints on a person's face and match those features against an existing representation of the user's face.  In state of the art applications, these systems are driven by deep computer vision.  In this project, we tackled two related, but simpler vision problems and deployed our algorithms and networks on a Raspberry Pi with camera.

### Face Detection

In the first part of this project, I used PCA on a large dataset of people's faces to determine the L2-distance between a sample face image projected in the PCA-space, and the so-called **eigen-faces**.  **Eigen-faces** are just eigen-vectors in the PCA-space.  By thresholding the distance between a sample projection and the eigen-vectors of the PCA-space, we can create a classifier for whether or not there is a face present in the picture.  A smaller L2-distance would mean that whatever pattern is in the image, is has features that resemble a human face, while a larger L2-distance would indicate that whatever is in the image does not have much similarity to a human face.  Shown below is a sample video of my detector deployed on a Raspberry Pi camera:

<video width="450" height="360" controls>
  <source type="video/mp4" src="/assets/img/facedetection.mp4">
</video>

The first step, as with any ML/CV project, is preprocessing.  The dataset prepared for students contains 2000 images of different human faces at various scales, all of which are 64x64 grayscaled images.  I vectorize all of the images in the dataset, and then compute the average for each pixel over all vectorized faces (\mu).  In order to make the data 0 centered, I subtract the average face vector from all samples.  Then, we can use our 0-centered data matrix to compute the covariance matrix of our data, with the following formula:

<p>
  [ Cov(X,X) = E(X - \mu)E(X - \mu)^T ]
<p/>

The expectation of the 0-centered data matrix is just the input itself, so our expression is simply:

<p>
  [ Cov(X,X) = (X - \mu)(X - \mu)^T ]
<p/>

By computing the eigenvectors of the covariance matrix, we now have a set of bases which describe our PCA-space.  Since the data matrix is of shape (2000x4096), the resulting dimensionality of the PCA-space comprised of the eigenvectors is at most 2000.  Eigenfaces are then generated by multiplying our 0-centered data matrix by the eigenvectors.  Eigenfaces with larger eigenvalues capture more variance than smaller eigenvalues, so we only really need to use the eigenfaces with the highest eigenvalues in order to correctly identify if there is a face present in an image.  Using the eigenface matrix, we can now compute the projection of an input image onto the span of the eigenbasis.  This is done by:

<p>
  [ \omega = eigenfaces \cdot (v - \mu)^T ]
  [ p = \omega^T \cdot eigenfaces ]
<p/>

where (v) is the vectorized sample image, and (p) is the vector projection of the sample image in the PCA-space.  Finally, we can take the projection and measure the L2 distance between the PCA-space projected vector, (p) and the 0-centered sample (v - \mu).

Next comes the implementation on the Raspberry Pi.  After SSH-ing into the Raspberry Pi and connecting to a server to stream camera data, we can process the frames using our above functions and OpenCV.  OpenCV comes in handy to read the streamed video frames from the rPi, but most of the processing is done by functions we wrote from above.  First, we constrain ourselves to detect within small rectangular region of the frame, shown visually by the square in the above video.  We also limit the number of eigenfaces used to compute the summed projection distance with the image in the rectangular region.  Tuning the number of eigenfaces to use for measurement, as well as the L2-distance threshold is left to students.  I found that using 20 eigenfaces and an L2-threshold of 47000 worked well, which is shown in the video.

### Mask Detection

<video width="450" height="360" controls>
  <source type="video/mp4" src="/assets/img/maskdetection.mp4">
</video>
