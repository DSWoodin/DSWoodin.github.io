---
layout: post
title: "The Role of Confidence, not Trust in Science"
date: 2017-06-23
---

[Kerr 1998]( http://journals.sagepub.com/doi/abs/10.1207/s15327957pspr0203_4?url_ver=Z39.88-2003&rfr_id=ori:rid:)

I recently listened to the latest episode of the Black Goat podcast (episode 10 – Nullius in verba) where their main topic was about the role of trust in science. 
The background to their discussion is that some researchers are resistant to the recent calls to publish papers having been pre-registered and having open data where possible. The murmurs are something along the lines of “we’re offended that you cannot take our word that we were honest with our analyses, and we should not need to share the data for you to believe the evidence we are presenting”. The consensus from the Black Goat team was that science should not rely on trust, and referred to the Royal Society’s motto ‘Nullius in verba’ or ‘Take nobody’s word for it’. My view largely parallels their discussion, but I thought I would take the opportunity to outline my view of the role of trust in science, and how it fits in with the recent developments in open science.

To cut a long story short, trust meaning ‘take my word for it’ has no place in science. Yes, it would be great to believe every article is a perfect representation of the study that was performed. However, it sadly isn’t an ideal world and as Chris Chambers outlines in his new book (7 deadly sins of psychology), the goal of science is at odds with making a career out of science. Researchers only publish positive results (REF) and they dress up their findings to make them as publishable as possible. This means that rather than honestly and transparently reporting their research, fields of research more closely represent a fun house mirror that makes everything warped. You can kind of see the result in the background, but the face and body is all distorted. In addition, the troubles facing psychological research have been the focus of numerous articles in the past few years and the issues have reached the public eye (REF). This means that the one thing that science is lacking is trust. Responding to a lack of trust means taking a real hard look at our distorted selves in the mirror, and there are groups of progressive researchers not liking what they see. 

From here, taking steps to increase trust firstly from other researchers and then from the public (how are we supposed to convince others if we can’t convince others working on the front line) typically gravitates toward making things more transparent. This has historically been seen in clinical trials where a series of high profile cases brought the integrity of the research into question and attracted public attention that doesn’t class as outreach. This was followed by a series of measures to increase the trust that can be placed in clinical trial research such as trial registers. More recently, psychology and biomedical science has gone through a similar process where the deficiencies reach the public’s attention. Like the response in clinical trials, psychologists need a way to increase the confidence other researchers and the public can place in their studies. This has led to several open science initiatives such as pre-registration, the PRO initiative (LINK), and open data. 

This brings us back to trust and confidence in science. Expecting readers to trust your article in the sense of ‘take my word for it, this finding is totally legit’ is not the way forward. Instead, we should be focusing on increasing the confidence readers have in our findings. Image a court case where someone has allegedly committed a crime and their lawyer is there to defend them. A lawyer could not stand there and say her client is innocent, I cannot show you the evidence, but take my word for it. Likewise, eyebrows would be raised if she said you do not need to look at the evidence yourselves, I have summarised it all in this tidy compelling paragraph. To make a solid case, you need to present all the evidence, you have to ensure people are confident in the conclusions you made. Bringing the analogy back to science, this necessitates that you should make people confident in your results by showing them you had planned to do it this way all along, and we can see your results aren’t the result of a mistake or misinterpretation. 

Instead of expecting people to take our word for it, we should be outlining the precautions we have taken to show that the results are robust. We should be pre-registering our research (it may not be perfect the first time around, but here’s how you can learn from my mistakes), allowing others to see the data unless you have a damn good reason that prevents you from sharing it, and we should be focusing on the reproducibility of results so people can appraise your methods. Building on these initiatives, hopefully we can ensure that the reader can be confident in the conclusions that we made, or give them the opportunity to show us why they were wrong. We should not be expecting people to trust our results unless they can it for themselves, frankly we are not in a position to ask for people’s trust. Science is often said to be self-correcting, but it can only be corrected if we can see what went wrong in the first place.  
