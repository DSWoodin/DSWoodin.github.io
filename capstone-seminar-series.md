---
layout: page
title: UBC MDS Capstone Seminar Series 2022

---

The UBC MDS Capstone Seminar Series is a collection of invited talks held for MDS-V and MDS-CL students, faculty and staff 
during the DSCI 591 Capstone Project course. Talks will be held from 2-3pm in DMP 310.

## Schedule

|Date|Speaker|Seminar Title|
|:---|:---:|:---:|
| 2022/05/13 | Scott Mackie, Amazon | TBD |
| 2022/05/20 | Zaid Haddad, Slalom | TBD |
| 2022/05/27 | Carrie Cheung, NuData Security, A Mastercard Company | TBD |
| 2022/06/03 | Adina Williams, Meta | TBD |
| 2022/06/10 | [Christo Kirov](#christo-kirov), Google | [Low-Resource Multilingual NLP at Google](#low-resource-multilingual-nlp-at-google) |
| 2022/06/17 | Capstone Presentations (no seminar series talk this week)| |
| 2022/06/24 | Maysam Emadi, Microsoft | TBD |

## Speaker Bio's

#### Christo Kirov
I'm currently a research software engineer at Google Research, working out of the NYC office. I'm interested in low-resource (both in terms of data and computational power) NLP in multilingual settings. I'm coming from a broad academic background - my undergraduate degree is in Computer Science and Linguistics, and I received my PhD in Cognitive Science from JHU. Afterwards, I worked as a PostDoc teaching NLP at the Georgetown Linguistics Department. Before moving to Google, I spent several years as a PostDoc at the JHU Center for Language and Speech Processing, working under a grant program called LORELEI (low-resource Languages for Emergent Incidents). A major focus was the development of resources for morphological processing, particularly UniMorph (<https://unimorph.github.io/>).

## Abstracts

#### Low-Resource Multilingual NLP at Google
by Christo Kirov, Google

As more and more users around the world access the Internet, especially on their smartphones, it becomes imperative to enable seamless interaction in their native language (see nextbillionusers.google). Unfortunately, support still lags behind for many languages outside of English. I'll discuss some of the challenges of building NLP models for these smaller languages for tasks such as language identification, translation, transliteration, and language modeling. In many cases, the development of new datasets (including open source efforts like UniMorph, Universal Dependencies, and Google's own Dakshina Dataset) plays a critical role in making progress.
